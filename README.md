# Statistical and Mathematical Methods for AI - Homework Notebooks

This repository contains implementations for four homework assignments from the Statistical and Mathematical Methods for AI course. Each notebook addresses specific mathematical and statistical topics relevant to artificial intelligence. Below are the main requirements and implementation details for each homework, with links to their respective notebooks.

---

## Homework 1: Linear Algebra and Floating Point Arithmetic

### Key Topics:
1. **Linear Systems**:
   - Solve \(Ax = b\) for various matrices (Random, Vandermonde, Hilbert).
   - Analyze condition numbers in \(2\)-norm and \(\infty\)-norm.
   - Compute and visualize relative errors.

2. **Floating Point Arithmetic**:
   - Compute machine epsilon \(\varepsilon\).
   - Analyze sequence convergence to \(e\).
   - Compute ranks and eigenvalues for sample matrices.

[Implementation in Notebook 1](./Homework_1.ipynb)

---

## Homework 2: Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA)

### Key Topics:
1. **Dimensionality Reduction**:
   - Implement PCA and LDA on subsets of the MNIST dataset.
   - Compare cluster distances and classification accuracy for different \(k\)-dimensions.

2. **Image Compression via SVD**:
   - Visualize dyads and \(k\)-rank approximations.
   - Analyze approximation error and compression factor.

[Implementation in Notebook 2](./Homework_2.ipynb)

---

## Homework 3: Optimization

### Key Topics:
1. **Gradient Descent (GD)**:
   - Implement GD with and without backtracking for step size.
   - Test on multiple functions (e.g., quadratic, Vandermonde-based).

2. **Stochastic Gradient Descent (SGD)**:
   - Implement SGD with batching and epochs.
   - Train a logistic regression classifier on subsets of the MNIST dataset.

[Implementation in Notebook 3](./Homework_3.ipynb)

---

## Homework 4: Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP)

### Key Topics:
1. **Polynomial Regression**:
   - Compute MLE and MAP solutions for polynomial fitting.
   - Analyze training and test errors across varying polynomial degrees and data sizes.

2. **Distribution Comparisons**:
   - Extend experiments with Poisson-distributed outputs.
   - Compare MLE and MAP under different noise assumptions.

[Implementation in Notebook 4](./Homework_4.ipynb)

